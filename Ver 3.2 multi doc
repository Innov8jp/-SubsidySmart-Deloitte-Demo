# DeloitteSmartâ„¢ AI Assistant â€“ Final UAT-Passed Version with Chat-Centric "Download Exec Report"

import streamlit as st
import openai
import fitz  # PyMuPDF for PDF parsing
from datetime import datetime
from openai import OpenAIError
from io import BytesIO
from PIL import Image
from fpdf import FPDF

# --- CONFIGURATION ---
st.set_page_config(
    page_title="DeloitteSmartâ„¢ - AI Assistant",
    page_icon=":moneybag:",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- OPENAI INITIALIZATION ---
openai_api_key = st.secrets.get("OPENAI_API_KEY")
if not openai_api_key:
    st.sidebar.error("âŒ OpenAI API key not found. Configure in Streamlit secrets.")
    st.stop()
openai.api_key = openai_api_key

# --- LANGUAGE TOGGLE ---
if "language" not in st.session_state:
    st.session_state.language = "English"
lang = st.sidebar.radio(
    "ğŸŒ Language / è¨€èª",
    ["English", "æ—¥æœ¬èª"],
    index=0
)
st.session_state.language = lang

def t(en: str, jp: str) -> str:
    return en if st.session_state.language == "English" else jp

# --- SIDEBAR BRANDING & ANALYTICS ---
st.sidebar.image("deloitte_logo.png", width=200)
st.sidebar.markdown("**Powered by Innov8**")
st.sidebar.markdown("Version 1.0 | Secure & Scalable")
st.sidebar.markdown("---")
st.sidebar.subheader(t("Analytics", "åˆ†æ"))
yes_count = sum(1 for f in st.session_state.get("feedback_entries", []) if f.get("helpful"))
no_count = sum(1 for f in st.session_state.get("feedback_entries", []) if not f.get("helpful"))
st.sidebar.metric(t("Helpful", "å¥½è©•"), yes_count)
st.sidebar.metric(t("Not Helpful", "ä¸è©•"), no_count)

# --- SESSION DEFAULTS ---
for key, default in {
    "chat_history": [],
    "document_content": {},
    "document_summary": {},
    "uploaded_filenames": [],
    "feedback_entries": []
}.items():
    if key not in st.session_state:
        st.session_state[key] = default

# --- MAIN LAYOUT ---
col_main, _ = st.columns([3, 1])
with col_main:
    st.title(
        t(
            "DeloitteSmartâ„¢: AI Assistant for M&A & Document Insights",
            "DeloitteSmartâ„¢: M&Aã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè§£æã®ãŸã‚ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
        )
    )

    # CAMERA OCR
    enable_cam = st.checkbox(t("ğŸ“¸ Enable Camera OCR", "ğŸ“¸ ã‚«ãƒ¡ãƒ©OCRã‚’æœ‰åŠ¹ã«ã™ã‚‹"), key="cam_toggle")
    if enable_cam:
        st.subheader(t("Document Capture & OCR", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ’®å½± & OCR"))
        tab_live, tab_upload = st.tabs([
            t("Live Capture", "ãƒ©ã‚¤ãƒ–æ’®å½±"),
            t("Upload Image", "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        ])
        with tab_live:
            img = st.camera_input(t("Capture via camera", "ã‚«ãƒ¡ãƒ©ã§æ’®å½±"))
        with tab_upload:
            img = st.file_uploader(
                t("Upload image file", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"),
                type=["png","jpg","jpeg"]
            )
        if img:
            st.image(img, use_container_width=True)
            if st.button(t("Extract Text from Image", "ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º")):
                try:
                    import pytesseract
                    from PIL import Image as PILImage
                    from io import BytesIO as _BytesIO
                    img_bytes = img.getvalue() if hasattr(img, "getvalue") else img.read()
                    img_pil = PILImage.open(_BytesIO(img_bytes))
                    text = pytesseract.image_to_string(img_pil)
                except ModuleNotFoundError:
                    st.error(t(
                        "pytesseract not installed. Please run `pip install pytesseract`.",
                        "pytesseractãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚`pip install pytesseract`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
                    ))
                    text = ""
                except Exception as e:
                    st.error(t(
                        f"OCR failed: {e}",
                        f"OCRã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"
                    ))
                    text = ""
                # Store and display
                st.session_state.document_content["Captured Image"] = text
                st.subheader(t("ğŸ“ Extracted Text", "ğŸ“ æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ"))
                st.text_area("", text, height=300)
# UPLOAD & SUMMARY
    with st.expander(t("ğŸ“ Upload & Summarize Documents", "ğŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ & è¦ç´„"), expanded=True):
        uploads = st.file_uploader(
            t("Select PDF/TXT files", "PDF/TXTã‚’é¸æŠ"),
            type=["pdf", "txt"], accept_multiple_files=True
        )
        for f in uploads:
            if f.name not in st.session_state.uploaded_filenames:
                try:
                    content = ""
                    if f.type == "application/pdf":
                        doc = fitz.open(stream=f.read(), filetype="pdf")
                        for p in doc: content += p.get_text()
                    else:
                        content = f.read().decode("utf-8")
                    st.session_state.document_content[f.name] = content
                    st.session_state.uploaded_filenames.append(f.name)
                    sumr = openai.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[
                            {"role":"system","content":"You are an expert AI consultant."},
                            {"role":"user","content":f"Summarize and ask 5 smart questions based on the document:\n{content}"}
                        ]
                    )
                    st.session_state.document_summary[f.name] = sumr.choices[0].message.content
                except OpenAIError as e:
                    st.error(f"Error processing {f.name}: {e}")

    # DISPLAY SUMMARIES
    if st.session_state.document_summary:
        st.subheader(t("ğŸ“„ Document Summaries & Questions", "ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè¦ç´„ & è³ªå•"))
        for doc, summ in st.session_state.document_summary.items():
            st.markdown(f"**ğŸ—‚ï¸ {doc}**")
            st.markdown(summ)
            st.markdown("---")

    # CHAT & Q&A
    st.subheader(t("Chat & Ask Questions", "ãƒãƒ£ãƒƒãƒˆ & è³ªå•"))
    user_prompt = st.chat_input(t("Type your question...", "è³ªå•ã‚’å…¥åŠ›..."))
    if user_prompt:
        docs = "\n\n".join(st.session_state.document_content.values())
        if not docs:
            st.warning(t("Please add or capture a document first.", "å…ˆã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’è¿½åŠ ã¾ãŸã¯æ’®å½±ã—ã¦ãã ã•ã„ã€‚"))
        else:
            st.session_state.chat_history.append({"role":"user","content":user_prompt})
            try:
                resp = openai.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[
                        {"role":"system","content":"You are a knowledgeable AI assistant."},
                        {"role":"user","content":f"{docs}\n\nQuestion: {user_prompt}"}
                    ]
                )
                ans = resp.choices[0].message.content
                st.session_state.chat_history.append({"role":"assistant","content":ans})
            except OpenAIError as e:
                st.error(f"OpenAI API Error: {e}")

    # DISPLAY CHAT HISTORY & FEEDBACK
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if msg["role"] == "assistant":
                col1, col2 = st.columns([1,1])
                if col1.button("ğŸ‘", key=f"yes_{len(st.session_state.feedback_entries)}"):
                    st.session_state.feedback_entries.append({"helpful":True,"timestamp":datetime.now().isoformat()})
                    st.success(t("Thanks for your feedback!", "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼"))
                if col2.button("ğŸ‘", key=f"no_{len(st.session_state.feedback_entries)}"):
                    st.session_state.feedback_entries.append({"helpful":False,"timestamp":datetime.now().isoformat()})
                    st.info(t("Feedback noted.", "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’è¨˜éŒ²ã—ã¾ã—ãŸã€‚"))

        # Download Exec Report button below chat history
    st.markdown("---")
    if st.button("Download Exec Report"):
        docs = st.session_state.document_content
        combined = "

".join([f"Document: {d}
{c}" for d,c in docs.items()])
        # Generate executive summary
        sumr = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role":"system","content":"You are a top-tier consultant AI."},
                {"role":"user","content":f"Provide an executive summary:
{combined}"}
            ]
        )
        exec_sum = sumr.choices[0].message.content
        # Generate smart questions
        qst = openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role":"system","content":"Generate 5 smart questions per document."},
                {"role":"user","content":f"Documents:
{combined}"}
            ]
        )
        questions = qst.choices[0].message.content
        # Build PDF report
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial","B",16)
        pdf.cell(0,10,"Exec Summary & Smart Questions",ln=1)
        pdf.set_font("Arial","",11)
        # Executive Summary section
        pdf.multi_cell(0,6,exec_sum)
        pdf.ln(4)
        # Smart Questions section
        pdf.set_font("Arial","B",12)
        pdf.cell(0,8,"Smart Questions",ln=1)
        pdf.set_font("Arial","",11)
        for line in questions.split("
"):
            pdf.multi_cell(0,6,line)
        buf = BytesIO()
        pdf.output(buf)
        buf.seek(0)
        st.download_button(
            "Download Exec Report",
            data=buf,
            file_name="Exec_Report.pdf",
            mime="application/pdf"
        )
# --- END ---

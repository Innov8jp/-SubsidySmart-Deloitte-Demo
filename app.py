# DeloitteSmartâ„¢ AI Assistant â€“ Final QA & UAT Version

import streamlit as st
import openai
import fitz  # PyMuPDF for PDF parsing
from datetime import datetime
from openai import OpenAIError
from io import BytesIO
from PIL import Image
from fpdf import FPDF
import pytesseract

# --- CONFIGURATION ---
st.set_page_config(
    page_title="DeloitteSmartâ„¢ - AI Assistant",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- OPENAI INIT ---
openai_api_key = st.secrets.get("OPENAI_API_KEY")
if not openai_api_key:
    st.sidebar.error("âŒ OpenAI API key not found. Configure in Streamlit secrets.")
    st.stop()
openai.api_key = openai_api_key

# --- LANGUAGE TOGGLE ---
if "language" not in st.session_state:
    st.session_state.language = "English"
lang = st.sidebar.radio("ğŸŒ Language / è¨€èª", ["English", "æ—¥æœ¬èª"], index=0)
st.session_state.language = lang

def t(en: str, jp: str) -> str:
    return en if st.session_state.language == "English" else jp

# --- SIDEBAR ANALYTICS ---
st.sidebar.image("deloitte_logo.png", width=200)
st.sidebar.markdown("**Powered by Innov8**")
st.sidebar.markdown("Version 1.0 | Secure & Scalable")
st.sidebar.markdown("---")
st.sidebar.subheader(t("Analytics", "åˆ†æ"))
yes_count = sum(1 for f in st.session_state.get("feedback_entries", []) if f.get("helpful"))
no_count = sum(1 for f in st.session_state.get("feedback_entries", []) if not f.get("helpful"))
st.sidebar.metric(t("Helpful", "å¥½è©•"), yes_count)
st.sidebar.metric(t("Not Helpful", "ä¸è©•"), no_count)

# --- SESSION STATE DEFAULTS ---
defaults = {
    "chat_history": [],
    "document_content": {},
    "document_summary": {},
    "uploaded_filenames": [],
    "feedback_entries": []
}
for key, val in defaults.items():
    if key not in st.session_state:
        st.session_state[key] = val

# --- MAIN AREA ---
col_main, _ = st.columns([3, 1])
with col_main:
    st.title(t(
        "DeloitteSmartâ„¢: AI Assistant for Deloitte Team",
        "DeloitteSmartâ„¢: ãƒ‡ãƒ­ã‚¤ãƒˆãƒãƒ¼ãƒ å‘ã‘AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ"
    ))

    # Camera OCR
    enable_cam = st.checkbox(t("ğŸ“¸ Enable Camera OCR", "ğŸ“¸ ã‚«ãƒ¡ãƒ©OCRã‚’æœ‰åŠ¹ã«ã™ã‚‹"))
    if enable_cam:
        st.subheader(t("Document Capture & OCR", "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ’®å½± & OCR"))
        tab1, tab2 = st.tabs([t("Live Capture", "ãƒ©ã‚¤ãƒ–æ’®å½±"), t("Upload Image", "ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")])

        with tab1:
            cam_img = st.camera_input(t("Capture via camera", "ã‚«ãƒ¡ãƒ©ã§æ’®å½±"), use_container_width=True)
            if cam_img and st.button(t("Extract Text from Camera", "ã‚«ãƒ¡ãƒ©ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"), key="extract_cam"):
                try:
                    cam_bytes = cam_img.getvalue()
                    cam_pil = Image.open(BytesIO(cam_bytes))
                    lang_code = "jpn" if st.session_state.language == "æ—¥æœ¬èª" else "eng"
                    try:
                        cam_text = pytesseract.image_to_string(cam_pil, lang=lang_code)
                    except pytesseract.TesseractError:
                        fallback_lang = "eng" if lang_code == "jpn" else "jpn"
                        st.warning(t(f"{lang_code.upper()} OCR not available. Switching to {fallback_lang.upper()}.",
                                     f"{lang_code.upper()} OCRã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚{fallback_lang.upper()}ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚"))
                        cam_text = pytesseract.image_to_string(cam_pil, lang=fallback_lang)
                    st.session_state.document_content["Camera Image"] = cam_text
                    st.subheader(t("ğŸ“ Extracted Text from Camera", "ğŸ“ ã‚«ãƒ¡ãƒ©ç”»åƒã‹ã‚‰ã®æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ"))
                    st.text_area("", cam_text, height=200)
                except Exception as e:
                    st.error(t(f"OCR failed: {e}", f"OCRã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"))

        with tab2:
            file_img = st.file_uploader(t("Upload image file", "ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"), type=["png", "jpg", "jpeg"])
            if file_img and st.button(t("Extract Text from Uploaded Image", "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"), key="extract_upload"):
                try:
                    file_bytes = file_img.getvalue()
                    file_pil = Image.open(BytesIO(file_bytes))
                    lang_code = "jpn" if st.session_state.language == "æ—¥æœ¬èª" else "eng"
                    file_text = pytesseract.image_to_string(file_pil, lang=lang_code)
                    st.session_state.document_content["Uploaded Image"] = file_text
                    st.subheader(t("ğŸ“ Extracted Text from Uploaded Image", "ğŸ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã‹ã‚‰ã®æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ"))
                    st.text_area("", file_text, height=200)
                except Exception as e:
                    st.error(t(f"OCR failed: {e}", f"OCRã«å¤±æ•—ã—ã¾ã—ãŸ: {e}"))

# --- END ---

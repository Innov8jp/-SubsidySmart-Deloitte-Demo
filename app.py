# DeloitteSmartâ„¢ AI Assistant â€“ Full Version (Enhanced Multi-Doc Summarizer, Persistent Chat, Feedback, Downloadable Report - Basic Chunking)

import streamlit as st
import openai
import fitz  # PyMuPDF
import json
from datetime import datetime
from openai import OpenAIError
import os
from io import BytesIO
import base64
import re  # Import regular expressions for splitting
import time # Import time (used implicitly by spinners/status)

# --- CONFIGURATION - MUST BE FIRST ---
# Set page configuration for the Streamlit app
st.set_page_config(
    page_title="DeloitteSmartâ„¢ - AI Assistant",
    page_icon=":moneybag:",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- CONSTANTS ---
# Maximum approximate characters to include in the chat prompt context from documents
# This is a heuristic based on token limits (~4 chars per token for English).
# GPT-3.5-turbo often has a 16k token limit, leaving room for prompt/response.
MAX_CONTEXT_CHARS = 14000
# Smaller chunk size used *before* joining into MAX_CONTEXT_CHARS.
# This size is used for the individual chunks stored and processed.
SPLIT_CHUNK_SIZE = 1500 # Slightly larger chunk size for better context within chunks

# --- LANGUAGE TOGGLE AND TRANSLATION FUNCTION ---
# Allow users to select language via a radio button in the sidebar
language = st.sidebar.radio("ðŸŒ Language / è¨€èªž", ["English", "æ—¥æœ¬èªž"], index=0, key="language_select")

# Dictionary containing English to Japanese translations
def get_translation(english_text):
    translations = {
        "DeloitteSmartâ„¢ - AI Assistant": "DeloitteSmartâ„¢ - AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
        "Faster, Smarter Decisions": "ã‚ˆã‚Šé€Ÿãã€ã‚ˆã‚Šã‚¹ãƒžãƒ¼ãƒˆãªæ„æ€æ±ºå®š",
        "ðŸ“ Upload Documents (PDF, TXT)": "ðŸ“ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (PDF, TXT)",
        "ðŸ“„ Summaries & Smart Questions": "ðŸ“„ è¦ç´„ã¨ã‚¹ãƒžãƒ¼ãƒˆãªè³ªå•",
        "ðŸ—‚ï¸": "ðŸ—‚ï¸",
        "---": "---",
        "ðŸ—£ï¸ Ask Questions Based on the Documents": "ðŸ—£ï¸ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦è³ªå•ã™ã‚‹",
        "Ask anything about the uploaded documents...": "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¤ã„ã¦ä½•ã§ã‚‚è³ªå•ã—ã¦ãã ã•ã„...",
        "ðŸ’¬ Chat History": "ðŸ’¬ ãƒãƒ£ãƒƒãƒˆå±¥æ­´",
        "User": "ãƒ¦ãƒ¼ã‚¶ãƒ¼",
        "Assistant": "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ",
        "â¬‡ï¸ Download Report": "â¬‡ï¸ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        "ðŸ“ Feedback": "ðŸ“ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯",
        "Share your feedback to help us improve:": "æ”¹å–„ã®ãŸã‚ã€ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ãŠèžã‹ã›ãã ã•ã„:",
        "Submit Feedback": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡",
        "Thank you for your feedback!": "ã”æ„è¦‹ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼",
        "Please enter your feedback.": "ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        "ðŸ“¬ Submitted Feedback": "ðŸ“¬ é€ä¿¡ã•ã‚ŒãŸãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯",
        "Timestamp": "ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—",
        "PDF extraction error for": "ã®PDFæŠ½å‡ºã‚¨ãƒ©ãƒ¼:",
        "Summary generation error for": "ã®è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼:",
        "Error during chat completion:": "ãƒãƒ£ãƒƒãƒˆå®Œäº†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:",
        "Error during document processing for": "ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼:",
        "You are a highly trained consultant. Summarize the following content and generate 5 smart questions to ask the client.": "ã‚ãªãŸã¯é«˜åº¦ãªè¨“ç·´ã‚’å—ã‘ãŸã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®å†…å®¹ã‚’è¦ç´„ã—ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«å°‹ã­ã‚‹ã¹ã5ã¤ã®ã‚¹ãƒžãƒ¼ãƒˆãªè³ªå•ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚",
        "Document:": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:",
        "Documents:": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ:", # Used for chat prompt context
        "Question:": "è³ªå•:",
        "# DeloitteSmartâ„¢ AI Assistant Report\n\n## Document Summaries:\n": "# DeloitteSmartâ„¢ AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆ\n\n## ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®è¦ç´„:\n",
        "## Chat History:\n": "## ãƒãƒ£ãƒƒãƒˆå±¥æ­´:\n",
        "Download Report": "ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        "Send": "é€ä¿¡",
        "Please upload documents before asking questions.": "è³ªå•ã™ã‚‹å‰ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
        "OpenAI API key is not available. Cannot generate summary.": "OpenAI APIã‚­ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è¦ç´„ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã€‚",
        "OpenAI API key is not available. Cannot answer questions.": "OpenAI APIã‚­ãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚",
        "Processing document": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ä¸­",
        "Extracting text from": "ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºä¸­:",
        "Splitting into chunks:": "ã«åˆ†å‰²ä¸­:",
        "Generating summary and questions for": "ã®è¦ç´„ã¨è³ªå•ã‚’ç”Ÿæˆä¸­:",
        "OpenAI API key is pre-configured.": "OpenAI APIã‚­ãƒ¼ã¯äº‹å‰ã«æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚",
        "OpenAI API key not found.": "OpenAI APIã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚",
        "Powered by [Innov8]": "[Innov8] æä¾›",
        "Prototype Version 1.0": "ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ— ãƒãƒ¼ã‚¸ãƒ§ãƒ³ 1.0",
        "Secure | Scalable | Smart": "å®‰å…¨ | ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ« | ã‚¹ãƒžãƒ¼ãƒˆ",
        "Note: This document is large and analysis uses chunks, which may impact summary/answer accuracy.": "æ³¨: ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã‚µã‚¤ã‚ºãŒå¤§ãã„ãŸã‚ã€åˆ†æžã«ã¯ãƒãƒ£ãƒ³ã‚¯ãŒä½¿ç”¨ã•ã‚Œã€è¦ç´„ã‚„å›žç­”ã®ç²¾åº¦ã«å½±éŸ¿ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
        "Generating response...": "å¿œç­”ã‚’ç”Ÿæˆä¸­...",
        "Sending query to AI...": "AIã«ã‚¯ã‚¨ãƒªã‚’é€ä¿¡ä¸­...",
        "Response received!": "å¿œç­”ã‚’å—ä¿¡ã—ã¾ã—ãŸï¼",
        "Error!": "ã‚¨ãƒ©ãƒ¼ï¼",
        "No document content available or chunks are too large to fit in context.": "åˆ©ç”¨å¯èƒ½ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒãªã„ã‹ã€ã¾ãŸã¯ãƒãƒ£ãƒ³ã‚¯ãŒå¤§ãã™ãŽã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŽã¾ã‚Šã¾ã›ã‚“ã€‚",
        "No text extracted from": "ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆãŒæŠ½å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ:",
        "Summary generation skipped (API key missing).": "è¦ç´„ç”Ÿæˆã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸ (APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“)ã€‚",
        "Error during document processing for": "ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå‡¦ç†ã‚¨ãƒ©ãƒ¼:",
        "Text extraction failed": "ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ",
        "Chunking failed": "ãƒãƒ£ãƒ³ã‚¯åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ",
        "Summary generation error for": "ã®è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼:",

    }
    return translations.get(english_text, english_text) if language == "æ—¥æœ¬èªž" else english_text

# --- HELPER FUNCTIONS ---

# Basic text splitting function to handle large documents
def split_text_into_chunks(text, chunk_size=SPLIT_CHUNK_SIZE):
    """Splits text by paragraphs, then joins into chunks of approximate size."""
    if not text:
        return []

    # Split by multiple newlines (paragraphs)
    paragraphs = re.split(r'\n\s*\n', text)

    chunks = []
    current_chunk = ""
    for para in paragraphs:
        # If adding the next paragraph makes the current chunk too large
        # (add +2 for the potential "\n\n" that will join them later)
        if len(current_chunk) + len(para) + 2 > chunk_size and current_chunk:
            chunks.append(current_chunk.strip())
            current_chunk = para.strip() # Start new chunk with this paragraph
        else:
            if current_chunk:
                current_chunk += "\n\n" + para.strip()
            else:
                current_chunk = para.strip()

    # Add the last chunk if it's not empty
    if current_chunk:
        chunks.append(current_chunk)

    # Secondary split for any chunks that are still too large (e.g., single massive paragraphs)
    final_chunks = []
    for chunk in chunks:
        if len(chunk) > chunk_size:
            # Simple character split as a fallback
            sub_chunks = [chunk[i:i+chunk_size] for i in range(0, len(chunk), chunk_size)]
            final_chunks.extend(sub_chunks)
        else:
            final_chunks.append(chunk)

    # Remove any empty strings resulting from splits
    return [c for c in final_chunks if c]

# --- SIDEBAR ---
# Set up the sidebar with logo, API key status, and branding
with st.sidebar:
    st.image("deloitte_logo.png", width=200) # Assuming deloitte_logo.png is in the same directory
    openai_api_key = st.secrets.get("OPENAI_API_KEY")
    if openai_api_key:
        st.sidebar.success(get_translation("OpenAI API key is pre-configured."))
    else:
        st.sidebar.error(get_translation("OpenAI API key not found."))
    st.sidebar.markdown(get_translation("Powered by [Innov8]"))
    st.sidebar.markdown(get_translation("Prototype Version 1
